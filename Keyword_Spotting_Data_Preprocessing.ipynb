{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4HaS8cEmrAoPyyP52kIUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TevinMusau/Integrating_Voice_to_Mobile_Payment_Systems_Using_Convolutional_Neural_Networks-A_Case_of_MPESA/blob/model/Keyword_Spotting_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "OFLptf1blwHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "hXyQPV2Nk1FD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Extract an audio feature for each audio sample (MFCC)\n",
        "- Store this in a JSON file"
      ],
      "metadata": {
        "id": "a8T3ec4wk_gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive to obtain the data and store it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# dataset path\n",
        "DATASET_PATH = \"/content/drive/MyDrive/ICS_PROJECT/Datasets/Dataset_1\"\n",
        "\n",
        "# preprocessed location to store the resulting json file\n",
        "JSON_PATH = \"/content/drive/MyDrive/ICS_PROJECT/Modules/Keyword_Spotting/Outputs/prepared_data.json\"\n",
        "\n",
        "# how many samples to consider for preprocessinng\n",
        "# 22050 is 1 second worth of sound in Librosa\n",
        "SAMPLES_TO_CONSIDER = 22050"
      ],
      "metadata": {
        "id": "hZZUy7mdl4x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e268f63-a012-4b2d-b789-8834817f8fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to prepare the data (it will go through all audio files, extract MFCCs and add them to a JSON file)\n",
        "# Params\n",
        "  # dataset_path = path to the data\n",
        "  # json_path = path to where the preprocessed data is saved\n",
        "  # n_mfcc = the number of coefficients we want to extract\n",
        "  # hop_length = tells us how big a segment should be in frames\n",
        "  # n_fft = \n",
        "\n",
        "def prepare_dataset(dataset_path, json_path, n_mfcc = 13, hop_length = 512, n_fft = 2048):\n",
        "  # data dictionary to store all the data we extract\n",
        "  data = {\n",
        "      \"mappings\": [],         # map key words to numbers\n",
        "      \"labels\": [],           # target value (outputs) for the above mappings\n",
        "      \"MFCCs\": [],            # inputs\n",
        "      \"files\": []             # file name with path\n",
        "  }\n",
        "\n",
        "  # loop through all the sub directories for the datasets\n",
        "  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "    \n",
        "    # we need to ensure we are not at a root level\n",
        "    if dirpath is not dataset_path:\n",
        "\n",
        "      # update the mappings\n",
        "      category = dirpath.split(\"/\") # split the name at the path e.g. dataset/down -> [dataset, down]\n",
        "      data[\"mappings\"].append(category[-1]) # append the last item in the list\n",
        "      print(f\"Processing {category}\")\n",
        "\n",
        "      # loop through all filenames and extract MFCCs\n",
        "      for f in filenames:\n",
        "\n",
        "        # get file path\n",
        "        file_path = os.path.join(dirpath, f) # join dirpath with filename\n",
        "\n",
        "        # load the audio file\n",
        "        signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "        # ensure the audio file is at least 1 sec\n",
        "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "\n",
        "          # enforce 1 sec long signal\n",
        "          signal = signal[:SAMPLES_TO_CONSIDER] # Consider the first second of data and ignore the rest\n",
        "\n",
        "          # extract the MFCCs\n",
        "          MFCCs = librosa.feature.mfcc(signal, n_mfcc = n_mfcc, hop_length = hop_length, n_fft = n_fft)\n",
        "\n",
        "          # store the data\n",
        "          data[\"labels\"].append(i-1)\n",
        "          data[\"MFCCs\"].append(MFCCs.T.tolist()) # transpose and cast to a list\n",
        "          data[\"files\"].append(file_path)\n",
        "          print(f\"{file_path}: {i-1}\")\n",
        "  \n",
        "  # store in a JSON file\n",
        "  # open a new file at \"json_path\" in write mode\n",
        "  with open(json_path, \"w\") as fp:\n",
        "    json.dump(data, fp, indent = 4)"
      ],
      "metadata": {
        "id": "pwN9zFf3FZjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_dataset(DATASET_PATH, JSON_PATH)"
      ],
      "metadata": {
        "id": "YQEeLW-8N2zP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}